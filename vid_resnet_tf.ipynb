{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvVu1hecJ0Wh"
      },
      "outputs": [],
      "source": [
        "!pip install PyAV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQtOurBoJ14y",
        "outputId": "5acec041-c59b-4edb-9466-a5b9dc7b570c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Lenovo\\dads-7202-final-project\\vid_mvit_tf.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/dads-7202-final-project/vid_mvit_tf.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/dads-7202-final-project/vid_mvit_tf.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/dads-7202-final-project/vid_mvit_tf.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/dads-7202-final-project')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFLGQh9BJrxy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.io import read_video\n",
        "from torchvision.datasets import VisionDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.video import mvit_v2_s,MViT_V2_S_Weights\n",
        "from torchvision.models.video import swin3d_t,Swin3D_T_Weights\n",
        "from torchvision.models.video import r2plus1d_18,R2Plus1D_18_Weights\n",
        "# from custom_dataset import CustomVidDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import  accuracy_score,precision_score,recall_score,f1_score,average_precision_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import gc\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4gyTul-XzKR"
      },
      "outputs": [],
      "source": [
        "# fix seed\n",
        "torch.manual_seed(12)\n",
        "random.seed(12)\n",
        "np.random.seed(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAMfPetiJrx1"
      },
      "outputs": [],
      "source": [
        "class CustomVidDataset(VisionDataset):\n",
        "    def __init__(self, annotations_file, vid_dir, transform= None, target_transform=None):\n",
        "        self.vid_labels = pd.read_csv(annotations_file)\n",
        "        self.vid_dir = vid_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.vid_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        vid_path = os.path.join(self.vid_dir, self.vid_labels.iloc[idx, 0])\n",
        "        vid,_,_ = read_video(vid_path,pts_unit='sec',end_pts=10.0,output_format='TCHW')\n",
        "        label = self.vid_labels.iloc[idx, 5:17]\n",
        "        array_label = label.to_numpy()\n",
        "        array_label = array_label.astype(int)\n",
        "        trans_vid = vid[:16] # slice only first 16 frames\n",
        "        if self.transform:\n",
        "            trans_vid = self.transform(trans_vid)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(array_label)\n",
        "        return trans_vid, array_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1ZlOb3aJrx2"
      },
      "outputs": [],
      "source": [
        "#Create Transform for preprocessing\n",
        "transforms_resnet = R2Plus1D_18_Weights.KINETICS400_V1.transforms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKbcD16oJrx2"
      },
      "outputs": [],
      "source": [
        "#Custom Dataset by Transform (Preprocess)\n",
        "PATH = '/content/drive/MyDrive/dads-7202-final-project/'\n",
        "\n",
        "def custom_data(model_type, transform):\n",
        "    train_data = CustomVidDataset(PATH + 'data/train_label.csv', PATH + 'data/train', transform=transform)\n",
        "    valid_data = CustomVidDataset(PATH + 'data/validate_label.csv', PATH + 'data/validate', transform=transform)\n",
        "    test_data = CustomVidDataset(PATH + 'data/test_label.csv', PATH + 'data/test', transform=transform)\n",
        "    return train_data, valid_data, test_data\n",
        "\n",
        "train_data_resnet, valid_data_resnet, test_data_resnet = custom_data('resnet', transforms_resnet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUL2JBFbJrx3"
      },
      "outputs": [],
      "source": [
        "#Create Data Loader\n",
        "def create_data_loader(dataset, batch_size=16, shuffle=True, num_workers=4):\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "train_dataset_resnet = create_data_loader(train_data_resnet)\n",
        "valid_dataset_resnet = create_data_loader(valid_data_resnet)\n",
        "test_dataset_resnet = create_data_loader(test_data_resnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvHjgFE7Jrx4",
        "outputId": "79c92740-b942-40e8-b701-a644968f472c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d81LoFKzDxG8",
        "outputId": "2d6c82cc-d346-47cf-dff0-4e2d8e084afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VideoResNet(\n",
            "  (stem): R2Plus1dStem(\n",
            "    (0): Conv3d(3, 45, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
            "    (1): BatchNorm3d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv3d(45, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "    (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "  )\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(64, 230, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(230, 128, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(128, 230, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(230, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(128, 288, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(288, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(128, 288, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(288, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(128, 460, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(460, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(460, 256, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(256, 460, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(460, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(460, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(256, 576, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(576, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(256, 576, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(576, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(256, 921, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(921, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(921, 512, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(512, 921, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(921, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(921, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(512, 1152, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(1152, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (conv2): Sequential(\n",
            "        (0): Conv2Plus1D(\n",
            "          (0): Conv3d(512, 1152, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "          (1): BatchNorm3d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv3d(1152, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        )\n",
            "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=400, bias=True)\n",
            "  (head): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=400, out_features=12, bias=True)\n",
            "    (2): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Set up Model\n",
        "model_resnet = r2plus1d_18(weights=\"KINETICS400_V1\")\n",
        "for param in model_resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model_resnet.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "model_resnet.head = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(400,12),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "print(model_resnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_VLOpS8Jrx4"
      },
      "outputs": [],
      "source": [
        "model_resnet = model_resnet.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8fREqFvJrx5"
      },
      "outputs": [],
      "source": [
        "#Create Loss Function and Optimizer\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "def create_optimizer(model, learning_rate=1e-3):\n",
        "    return torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "optimizer_resnet = create_optimizer(model_resnet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRjXOsCtyUHC"
      },
      "outputs": [],
      "source": [
        "def scoring(y_true,prediction):\n",
        "\n",
        "    acc = accuracy_score(y_true,prediction)\n",
        "\n",
        "    f1s = f1_score(y_true,prediction,average = 'samples', zero_division=0)\n",
        "\n",
        "    rec_s = recall_score(y_true,prediction,average = 'samples', zero_division=0)\n",
        "\n",
        "    preci_s = precision_score(y_true,prediction,average = 'samples', zero_division=0)\n",
        "\n",
        "    ap_s = average_precision_score(y_true,prediction,average = 'samples')\n",
        "    return acc,f1s,rec_s,preci_s,ap_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m13c_JEkJrx5"
      },
      "outputs": [],
      "source": [
        "def train(train_dataset,valid_dataset, model, loss_fn, optimizer):\n",
        "\n",
        "    num_label = 12\n",
        "    class_label = list(range(num_label))\n",
        "    label_binarizer = MultiLabelBinarizer(classes=class_label)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.\n",
        "    valid_loss = 0.\n",
        "    train_y_true_lst = []\n",
        "    train_y_pred_lst = []\n",
        "\n",
        "    valid_y_true_lst = []\n",
        "    valid_y_pred_lst = []\n",
        "\n",
        "    for data in train_dataset:\n",
        "        # print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
        "        X, y = data\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        #  clear the grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # predict\n",
        "        pred = model(X)\n",
        "        # compute loss\n",
        "        loss = loss_fn(pred, y.float())\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        # update new weight\n",
        "        optimizer.step()\n",
        "\n",
        "        round_pred = np.round(pred.detach().cpu())\n",
        "\n",
        "        train_loss += loss.item()*X.size(0)\n",
        "        train_y_true_lst.append(y.cpu())\n",
        "        train_y_pred_lst.append(round_pred)\n",
        "\n",
        "        # delete locals\n",
        "        del X\n",
        "        del y\n",
        "        del loss\n",
        "        del pred\n",
        "\n",
        "        # clean the cache\n",
        "        if device == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "        elif device == \"mps\":\n",
        "            torch.mps.empty_cache()\n",
        "        # collect the garbage\n",
        "        gc.collect()\n",
        "\n",
        "    # evaluation\n",
        "    model.eval()\n",
        "    for data in valid_dataset:\n",
        "        X, y = data\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # predict\n",
        "        pred = model(X)\n",
        "        # compute loss\n",
        "        loss = loss_fn(pred, y.float())\n",
        "\n",
        "        round_pred = np.round(pred.detach().cpu())\n",
        "\n",
        "        valid_loss += loss.item()*X.size(0)\n",
        "        valid_y_true_lst.append(y.cpu())\n",
        "        valid_y_pred_lst.append(round_pred)\n",
        "\n",
        "        # delete locals\n",
        "        del X\n",
        "        del y\n",
        "        del loss\n",
        "        del pred\n",
        "\n",
        "        # clean the cache\n",
        "        if device == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "        elif device == \"mps\":\n",
        "            torch.mps.empty_cache()\n",
        "        # collect the garbage\n",
        "        gc.collect()\n",
        "\n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = train_loss/len(train_dataset.sampler)\n",
        "    valid_loss = valid_loss/len(valid_dataset.sampler)\n",
        "\n",
        "    train_y_pred = torch.cat(train_y_pred_lst, dim=0).numpy()\n",
        "    train_y_pred = label_binarizer.fit_transform(train_y_pred)\n",
        "\n",
        "    train_y_true = torch.cat(train_y_true_lst, dim=0).numpy()\n",
        "    train_y_true = label_binarizer.fit_transform(train_y_true)\n",
        "\n",
        "    valid_y_pred = torch.cat(valid_y_pred_lst, dim=0).numpy()\n",
        "    valid_y_pred = label_binarizer.fit_transform(valid_y_pred)\n",
        "\n",
        "    valid_y_true = torch.cat(valid_y_true_lst, dim=0).numpy()\n",
        "    valid_y_true = label_binarizer.fit_transform(valid_y_true)\n",
        "\n",
        "    t_acc,t_f1s,t_rec_s,t_preci_s,t_ap_s = scoring(train_y_true,train_y_pred)\n",
        "    v_acc,v_f1s,v_rec_s,v_preci_s,v_ap_s = scoring(valid_y_true,valid_y_pred)\n",
        "    print(f\"AVG Training Loss: {round(train_loss,4)}\\nAVG Validation Loss: {round(valid_loss,4)}\")\n",
        "    print(f\"Accuracy: {round(t_acc,4)}\\nF1: {round(t_f1s,4)}\\nRecall: {round(t_rec_s,4)}\\nPrecision: {round(t_preci_s,4)}\\nAP: {round(t_ap_s,4)}\")\n",
        "    return train_loss,valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mo-CFT_yBxc"
      },
      "outputs": [],
      "source": [
        "def test(test_dataset, model, loss_fn):\n",
        "\n",
        "  num_label = 12\n",
        "  class_label = list(range(num_label))\n",
        "  label_binarizer = MultiLabelBinarizer(classes=class_label)\n",
        "\n",
        "  test_loss = 0.\n",
        "  test_y_true_lst = []\n",
        "  test_y_pred_lst = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for data in valid_dataset_mvit:\n",
        "      X, y = data\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y.float())\n",
        "\n",
        "      round_pred = np.round(pred.detach().cpu())\n",
        "\n",
        "      test_loss += loss.item()*X.size(0)\n",
        "      test_y_true_lst.append(y.cpu())\n",
        "      test_y_pred_lst.append(round_pred)\n",
        "\n",
        "    test_loss = test_loss/len(train_dataset_mvit.sampler)\n",
        "\n",
        "    y_pred = torch.cat(test_y_pred_lst, dim=0).numpy()\n",
        "    y_pred = label_binarizer.fit_transform(y_pred)\n",
        "\n",
        "    y_true = torch.cat(test_y_true_lst, dim=0).numpy()\n",
        "    y_true = label_binarizer.fit_transform(y_true)\n",
        "\n",
        "    acc,f1s,rec_s,preci_s,ap_s = scoring(y_true,y_pred)\n",
        "\n",
        "    print(f\"AVG Test Loss: {round(test_loss,4)}\")\n",
        "    print(f\"Accuracy: {round(acc,4)}\\nF1: {round(f1s,4)}\\nRecall: {round(rec_s,4)}\\nPrecision: {round(preci_s,4)}\\nAP: {round(ap_s,4)}\")\n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzatOjy8DxG9"
      },
      "outputs": [],
      "source": [
        "#Train Model\n",
        "all_train_loss_resnet = []\n",
        "all_valid_loss_resnet = []\n",
        "epochs = 1\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss_resnet, valid_loss_resnet = train(train_dataset_resnet,valid_dataset_resnet, model_resnet, loss_fn, optimizer_resnet)\n",
        "    all_train_loss_resnet.append(train_loss_resnet)\n",
        "    all_valid_loss_resnet.append(all_valid_loss_resnet)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iV7qBj2DxG9"
      },
      "outputs": [],
      "source": [
        "#Test Model\n",
        "test_loss_resnet = test(test_dataset_resnet,model_resnet,loss_fn)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}