{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install liac-arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "file_df = pd.read_csv('data/data_set_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = file_df.loc[:, ['filename']].to_numpy()\n",
    "y = file_df.loc[:, [\"Healthy Lifestyle and Weight Loss\", \"Weight Lifting\", \"Running\", \"Yoga\", \"Haircare\", \"Makeup\", \"Skincare\", \"Outfit\", \"Accommodation\", \"Adventure\", \"Culture\", \"Food and drink\"]].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.dataset import load_dataset\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "#X, y, _, _ = load_dataset('scene', 'undivided')\n",
    "\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X, y, test_size=0.1)\n",
    "X_train, y_train, X_val, y_val = iterative_train_test_split(X, y, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection.measures import get_combination_wise_output_matrix\n",
    "from collections import Counter\n",
    "\n",
    "pd.DataFrame({\n",
    "    'train': Counter(str(combination) for row in get_combination_wise_output_matrix(y_train, order=2) for combination in row),\n",
    "    'test' : Counter(str(combination) for row in get_combination_wise_output_matrix(y_test, order=2) for combination in row),\n",
    "    'validation' : Counter(str(combination) for row in get_combination_wise_output_matrix(y_val, order=2) for combination in row)\n",
    "}).T.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0], X_test.shape[0], X_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape[0], y_test.shape[0], y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Column name\n",
    "train_column = [\"filename\"]\n",
    "\n",
    "# Create a DataFrame\n",
    "train_df = pd.DataFrame(X_train, columns = train_column)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column with the same length as the DataFrame\n",
    "train_df[\"data_split\"] = [\"train\"] * len(train_df)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Column name\n",
    "test_column = [\"filename\"]\n",
    "\n",
    "# Create a DataFrame\n",
    "test_df = pd.DataFrame(X_test, columns = test_column)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column with the same length as the DataFrame\n",
    "test_df[\"data_split\"] = [\"test\"] * len(test_df)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Column name\n",
    "val_column = [\"filename\"]\n",
    "\n",
    "# Create a DataFrame\n",
    "val_df = pd.DataFrame(X_val, columns = test_column)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column with the same length as the DataFrame\n",
    "val_df[\"data_split\"] = [\"validation\"] * len(val_df)\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "print(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.concat([train_df, test_df, val_df], axis=0)\n",
    "\n",
    "# Display the concatenated DataFrame along columns\n",
    "print(concat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join\n",
    "join_df = pd.merge(file_df, concat_df, on = \"filename\")\n",
    "print(join_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the CSV file\n",
    "#csv_file_path = 'data/data_set_label.csv'\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "#join_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "#print(f'DataFrame exported to CSV file: {csv_file_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = concat_df['data_split'].value_counts().get('train', 0)\n",
    "test_count = concat_df['data_split'].value_counts().get('test', 0)\n",
    "val_count = concat_df['data_split'].value_counts().get('validation', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data_data = {'data_for': ['train', 'test', 'validation'],\n",
    "        'value': [train_count, test_count, val_count]}\n",
    "\n",
    "data_df = pd.DataFrame(data_data)\n",
    "\n",
    "# Plot a bar chart\n",
    "plt.bar(data_df['data_for'], data_df['value'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Data For')\n",
    "plt.ylabel('Numbers of Data')\n",
    "plt.title('Numbers of Data Split')\n",
    "\n",
    "for i, value in enumerate(data_df['value']):\n",
    "    plt.text(i, value + 0.5, str(value), ha='center', va='bottom')\n",
    "    \n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['No', 'filename', 'Links', 'main_label', 'sub_label', 'duration', 'frame_count', 'height', 'width', 'fps', 'data_split']\n",
    "\n",
    "# Drop the specified columns\n",
    "eda_sub_df = file_df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(eda_sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the occurrences of 1 in each column\n",
    "sub_column_sums =eda_sub_df.sum(axis=0)\n",
    "print(sub_column_sums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame from the result\n",
    "result_sub_df = pd.DataFrame({'Sub Label Name': sub_column_sums.index, 'Counts': sub_column_sums.values})\n",
    "print(result_sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bar chart\n",
    "plt.bar(result_sub_df['Sub Label Name'], result_sub_df['Counts'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Sub Label Names')\n",
    "plt.ylabel('Numbers of Data')\n",
    "plt.title('Check for Data Balancing for each Sub-Labels')\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "\n",
    "# Annotate each bar with its corresponding value\n",
    "for i, value in enumerate(result_sub_df['Counts']):\n",
    "    plt.text(i, value + 0.5, str(value), ha='center', va='bottom')\n",
    "    \n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'duration' column\n",
    "duration_column = file_df['duration']\n",
    "\n",
    "# Calculate max, min, mean, and standard deviation\n",
    "max_duration = duration_column.max()\n",
    "min_duration = duration_column.min()\n",
    "mean_duration = duration_column.mean()\n",
    "std_dev_duration = duration_column.std()\n",
    "\n",
    "# Print the results\n",
    "print(f'Max Duration: {max_duration}')\n",
    "print(f'Min Duration: {min_duration}')\n",
    "print(f'Mean Duration: {mean_duration}')\n",
    "print(f'Standard Deviation Duration: {std_dev_duration}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "plt.hist(duration_column, bins=20, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Duration')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "plt.hist(duration_column, bins=20, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Duration')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Duration')\n",
    "\n",
    "# Add vertical lines for mean and standard deviation\n",
    "plt.axvline(mean_duration, color='red', linestyle='dashed', linewidth=2, label='Mean')\n",
    "plt.axvline(min_duration, color='blue', linestyle='dashed', linewidth=2, label='Min')\n",
    "plt.axvline(max_duration, color='blue', linestyle='dashed', linewidth=2, label='Max')\n",
    "\n",
    "plt.legend(loc='upper center')\n",
    "\n",
    "# Add labels for min, max, mean, and sd\n",
    "plt.text(min_duration, 0, f'Min: {min_duration:.1f}', rotation=45, va='top', ha = 'right')\n",
    "plt.text(max_duration, 0, f'Max: {max_duration:.1f}', rotation=45, va='top', ha='right')\n",
    "plt.text(mean_duration, 0, f'Mean: {mean_duration:.1f}', rotation=45, va='top', ha='right')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the range of duration for each sub_label\n",
    "sub_label_ranges = file_df.groupby('sub_label')['duration'].agg(['min', 'max', 'mean'])\n",
    "\n",
    "#Plot a bar chart\n",
    "ax = sub_label_ranges.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "# Add numbers to y-axis\n",
    "#for i, (min_val, max_val, mean_val) in enumerate(zip(sub_label_ranges['min'], sub_label_ranges['max'], sub_label_ranges['mean'])):\n",
    "#    ax.text(i, max_val, f'{max_val:.0f}', ha='center', va='top', color='green')\n",
    "#    ax.text(i, mean_val, f'{mean_val:.0f}', ha='center', va='bottom', color='black')\n",
    "#    ax.text(i, min_val, f'{min_val:.0f}', ha='center', va='bottom', color='blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv('data/train_label.csv')\n",
    "test_label = pd.read_csv('data/test_label.csv')\n",
    "val_label = pd.read_csv('data/validate_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_drop = ['No', 'filename', 'Links', 'main_label', 'sub_label', 'duration', 'frame_count', 'height', 'width', 'fps', 'data_split']\n",
    "\n",
    "# Drop the specified columns\n",
    "train_sub_df = train_label.drop(columns=train_to_drop)\n",
    "\n",
    "print(train_sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of 1s for each column\n",
    "count_series_train = train_sub_df.sum()\n",
    "\n",
    "# Plot the bar chart\n",
    "count_series_train.plot(kind='bar', figsize=(10, 6), color='green')\n",
    "plt.title('amounts of Trian Dataset for Each Sub-Label')\n",
    "plt.xlabel('Sub-Label Names')\n",
    "plt.ylabel('Amounts')\n",
    "\n",
    "for i, v in enumerate(count_series_train):\n",
    "    plt.text(i, v + 0.1, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_drop = ['No', 'filename', 'Links', 'main_label', 'sub_label', 'duration', 'frame_count', 'height', 'width', 'fps', 'data_split']\n",
    "\n",
    "# Drop the specified columns\n",
    "test_sub_df = test_label.drop(columns=test_to_drop)\n",
    "\n",
    "print(test_sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of 1s for each column\n",
    "count_series_test = test_sub_df.sum()\n",
    "\n",
    "# Plot the bar chart\n",
    "count_series_test.plot(kind='bar', figsize=(10, 6), color='blue')\n",
    "plt.title('amounts of Trian Dataset for Each Sub-Label')\n",
    "plt.xlabel('Sub-Label Names')\n",
    "plt.ylabel('Amounts')\n",
    "\n",
    "for i, v in enumerate(count_series_test):\n",
    "    plt.text(i, v + 0.1, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_to_drop = ['No', 'filename', 'Links', 'main_label', 'sub_label', 'duration', 'frame_count', 'height', 'width', 'fps', 'data_split']\n",
    "\n",
    "# Drop the specified columns\n",
    "val_sub_df = val_label.drop(columns=test_to_drop)\n",
    "\n",
    "print(val_sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of 1s for each column\n",
    "count_series_val = val_sub_df.sum()\n",
    "\n",
    "# Plot the bar chart\n",
    "count_series_val.plot(kind='bar', figsize=(10, 6), color='orange')\n",
    "plt.title('amounts of Trian Dataset for Each Sub-Label')\n",
    "plt.xlabel('Sub-Label Names')\n",
    "plt.ylabel('Amounts')\n",
    "\n",
    "for i, v in enumerate(count_series_val):\n",
    "    plt.text(i, v + 0.1, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_to_drop = ['No', 'filename', 'Links', 'main_label', 'sub_label', 'frame_count', 'height', 'width', 'fps', 'data_split']\n",
    "\n",
    "#Drop the specified columns\n",
    "train_dur_df = train_label.drop(columns=train_to_drop)\n",
    "\n",
    "print(train_dur_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_drop = ['No', 'filename', 'Links', 'main_label', 'sub_label', 'frame_count', 'height', 'width', 'fps', 'data_split']\n",
    "\n",
    "# Drop the specified columns\n",
    "test_dur_df = test_label.drop(columns=test_to_drop)\n",
    "\n",
    "print(test_dur_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_to_drop = ['No', 'filename', 'Links', 'main_label', 'sub_label', 'frame_count', 'height', 'width', 'fps', 'data_split']\n",
    "\n",
    "# Drop the specified columns\n",
    "val_dur_df = val_label.drop(columns=val_to_drop)\n",
    "\n",
    "print(val_dur_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the product of 'duration' and each of the other 12 columns\n",
    "product_df_train = train_dur_df.copy()  # Copy the original DataFrame\n",
    "\n",
    "# Multiply each column (except 'duration') by the 'duration'\n",
    "for col in train_dur_df.columns[:-1]:  # Exclude the last column 'duration'\n",
    "    product_df_train[col] = product_df_train[col] * product_df_train['duration']\n",
    "\n",
    "# Drop the 'duration' column as it's no longer needed\n",
    "product_df_train = product_df_train.drop(columns=['duration'])\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(product_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate min, max, and mean of each column\n",
    "stats_df = product_df_train.describe().loc[['min', 'max', 'mean']]\n",
    "\n",
    "# Create a bar chart for each column\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for column in stats_df.columns:\n",
    "    # Bar chart for each column\n",
    "    plt.bar(column, stats_df.loc['max', column] - stats_df.loc['min', column], label=column, color='skyblue')\n",
    "\n",
    "    # Add labels for min, max, and mean values at different heights\n",
    "    plt.text(column, stats_df.loc['max', column] - 0.3 * (stats_df.loc['max', column] - stats_df.loc['min', column]),\n",
    "             f\"Max: {stats_df.loc['max', column]:.2f}\", ha='center', va='bottom', rotation=45, fontsize=8)\n",
    "    \n",
    "    plt.text(column, stats_df.loc['max', column] - 0.5 * (stats_df.loc['max', column] - stats_df.loc['min', column]),\n",
    "             f\"Mean: {stats_df.loc['mean', column]:.2f}\", ha='center', va='bottom', rotation=45, fontsize=8)\n",
    "\n",
    "# Configure plot labels and legend\n",
    "plt.title(\"Ranges of Video Duration for Each Sub-Label\")\n",
    "plt.xlabel(\"Sub-Labels names\")\n",
    "plt.ylabel(\"Video Duration Ranges\")\n",
    "plt.xticks(rotation=90, ha='center')\n",
    "\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.25, 1.0))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
