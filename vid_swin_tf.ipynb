{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvVu1hecJ0Wh"
      },
      "outputs": [],
      "source": [
        "!pip install PyAV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQtOurBoJ14y",
        "outputId": "5acec041-c59b-4edb-9466-a5b9dc7b570c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Lenovo\\dads-7202-final-project\\vid_mvit_tf.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/dads-7202-final-project/vid_mvit_tf.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/dads-7202-final-project/vid_mvit_tf.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Lenovo/dads-7202-final-project/vid_mvit_tf.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/dads-7202-final-project')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFLGQh9BJrxy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.io import read_video\n",
        "from torchvision.datasets import VisionDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.video import mvit_v2_s,MViT_V2_S_Weights\n",
        "from torchvision.models.video import swin3d_t,Swin3D_T_Weights\n",
        "from torchvision.models.video import r2plus1d_18,R2Plus1D_18_Weights\n",
        "# from custom_dataset import CustomVidDataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import  accuracy_score,precision_score,recall_score,f1_score,average_precision_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import gc\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4gyTul-XzKR"
      },
      "outputs": [],
      "source": [
        "# fix seed\n",
        "torch.manual_seed(12)\n",
        "random.seed(12)\n",
        "np.random.seed(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAMfPetiJrx1"
      },
      "outputs": [],
      "source": [
        "class CustomVidDataset(VisionDataset):\n",
        "    def __init__(self, annotations_file, vid_dir, transform= None, target_transform=None):\n",
        "        self.vid_labels = pd.read_csv(annotations_file)\n",
        "        self.vid_dir = vid_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.vid_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        vid_path = os.path.join(self.vid_dir, self.vid_labels.iloc[idx, 0])\n",
        "        vid,_,_ = read_video(vid_path,pts_unit='sec',end_pts=10.0,output_format='TCHW')\n",
        "        label = self.vid_labels.iloc[idx, 5:17]\n",
        "        array_label = label.to_numpy()\n",
        "        array_label = array_label.astype(int)\n",
        "        trans_vid = vid[:16] # slice only first 16 frames\n",
        "        if self.transform:\n",
        "            trans_vid = self.transform(trans_vid)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(array_label)\n",
        "        return trans_vid, array_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1ZlOb3aJrx2"
      },
      "outputs": [],
      "source": [
        "#Create Transform for preprocessing\n",
        "transforms_swin = Swin3D_T_Weights.KINETICS400_V1.transforms()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKbcD16oJrx2"
      },
      "outputs": [],
      "source": [
        "#Custom Dataset by Transform (Preprocess)\n",
        "PATH = '/content/drive/MyDrive/dads-7202-final-project/'\n",
        "\n",
        "def custom_data(model_type, transform):\n",
        "    train_data = CustomVidDataset(PATH + 'data/train_label.csv', PATH + 'data/train', transform=transform)\n",
        "    valid_data = CustomVidDataset(PATH + 'data/validate_label.csv', PATH + 'data/validate', transform=transform)\n",
        "    test_data = CustomVidDataset(PATH + 'data/test_label.csv', PATH + 'data/test', transform=transform)\n",
        "    return train_data, valid_data, test_data\n",
        "\n",
        "train_data_swin, valid_data_swin, test_data_swin = custom_data('swin', transforms_swin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUL2JBFbJrx3"
      },
      "outputs": [],
      "source": [
        "#Create Data Loader\n",
        "def create_data_loader(dataset, batch_size=16, shuffle=True, num_workers=4):\n",
        "    return DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "train_dataset_swin = create_data_loader(train_data_swin)\n",
        "valid_dataset_swin = create_data_loader(valid_data_swin)\n",
        "test_dataset_swin = create_data_loader(test_data_swin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvHjgFE7Jrx4",
        "outputId": "79c92740-b942-40e8-b701-a644968f472c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpcwAvOwDxG8",
        "outputId": "dd9c61cf-ae4a-4c4b-b702-4bc4773b5254",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SwinTransformer3d(\n",
            "  (patch_embed): PatchEmbed3d(\n",
            "    (proj): Conv3d(3, 96, kernel_size=(2, 4, 4), stride=(2, 4, 4))\n",
            "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "  (features): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): SwinTransformerBlock(\n",
            "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): ShiftedWindowAttention3d(\n",
            "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
            "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): MLP(\n",
            "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): SwinTransformerBlock(\n",
            "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): ShiftedWindowAttention3d(\n",
            "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.009090909090909092, mode=row)\n",
            "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): MLP(\n",
            "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): PatchMerging(\n",
            "      (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
            "      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): SwinTransformerBlock(\n",
            "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): ShiftedWindowAttention3d(\n",
            "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.018181818181818184, mode=row)\n",
            "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): MLP(\n",
            "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): SwinTransformerBlock(\n",
            "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): ShiftedWindowAttention3d(\n",
            "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.02727272727272728, mode=row)\n",
            "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): MLP(\n",
            "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (3): PatchMerging(\n",
            "      (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
            "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (0): SwinTransformerBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): ShiftedWindowAttention3d(\n",
            "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.03636363636363637, mode=row)\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): MLP(\n",
            "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): SwinTransformerBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): ShiftedWindowAttention3d(\n",
            "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.045454545454545456, mode=row)\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): MLP(\n",
            "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): SwinTransformerBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): ShiftedWindowAttention3d(\n",
            "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.05454545454545456, mode=row)\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): MLP(\n",
            "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): SwinTransformerBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): ShiftedWindowAttention3d(\n",
            "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.06363636363636364, mode=row)\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): MLP(\n",
            "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): SwinTransformerBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): ShiftedWindowAttention3d(\n",
            "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.07272727272727274, mode=row)\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): MLP(\n",
            "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): SwinTransformerBlock(\n",
            "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): ShiftedWindowAttention3d(\n",
            "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.08181818181818182, mode=row)\n",
            "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): MLP(\n",
            "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (5): PatchMerging(\n",
            "      (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
            "      (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): SwinTransformerBlock(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): ShiftedWindowAttention3d(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.09090909090909091, mode=row)\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): MLP(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): SwinTransformerBlock(\n",
            "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): ShiftedWindowAttention3d(\n",
            "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
            "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): MLP(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Dropout(p=0.0, inplace=False)\n",
            "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (4): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  (avgpool): AdaptiveAvgPool3d(output_size=1)\n",
            "  (head): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=768, out_features=12, bias=True)\n",
            "    (2): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#Set up Model\n",
        "model_swin = swin3d_t(weights=\"KINETICS400_V1\")\n",
        "for param in model_swin.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model_swin.features[6].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "model_swin.head = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(768,12),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "print(model_swin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_VLOpS8Jrx4"
      },
      "outputs": [],
      "source": [
        "model_swin = model_swin.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8fREqFvJrx5"
      },
      "outputs": [],
      "source": [
        "#Create Loss Function and Optimizer\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "def create_optimizer(model, learning_rate=1e-3):\n",
        "    return torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "optimizer_mvit = create_optimizer(model_mvit)\n",
        "optimizer_swin = create_optimizer(model_swin)\n",
        "optimizer_resnet = create_optimizer(model_resnet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRjXOsCtyUHC"
      },
      "outputs": [],
      "source": [
        "def scoring(y_true,prediction):\n",
        "\n",
        "    acc = accuracy_score(y_true,prediction)\n",
        "\n",
        "    f1s = f1_score(y_true,prediction,average = 'samples', zero_division=0)\n",
        "\n",
        "    rec_s = recall_score(y_true,prediction,average = 'samples', zero_division=0)\n",
        "\n",
        "    preci_s = precision_score(y_true,prediction,average = 'samples', zero_division=0)\n",
        "\n",
        "    ap_s = average_precision_score(y_true,prediction,average = 'samples')\n",
        "    return acc,f1s,rec_s,preci_s,ap_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m13c_JEkJrx5"
      },
      "outputs": [],
      "source": [
        "def train(train_dataset,valid_dataset, model, loss_fn, optimizer):\n",
        "\n",
        "    num_label = 12\n",
        "    class_label = list(range(num_label))\n",
        "    label_binarizer = MultiLabelBinarizer(classes=class_label)\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    train_loss = 0.\n",
        "    valid_loss = 0.\n",
        "    train_y_true_lst = []\n",
        "    train_y_pred_lst = []\n",
        "\n",
        "    valid_y_true_lst = []\n",
        "    valid_y_pred_lst = []\n",
        "\n",
        "    for data in train_dataset:\n",
        "        # print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
        "        X, y = data\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        #  clear the grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # predict\n",
        "        pred = model(X)\n",
        "        # compute loss\n",
        "        loss = loss_fn(pred, y.float())\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        # update new weight\n",
        "        optimizer.step()\n",
        "\n",
        "        round_pred = np.round(pred.detach().cpu())\n",
        "\n",
        "        train_loss += loss.item()*X.size(0)\n",
        "        train_y_true_lst.append(y.cpu())\n",
        "        train_y_pred_lst.append(round_pred)\n",
        "\n",
        "        # delete locals\n",
        "        del X\n",
        "        del y\n",
        "        del loss\n",
        "        del pred\n",
        "\n",
        "        # clean the cache\n",
        "        if device == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "        elif device == \"mps\":\n",
        "            torch.mps.empty_cache()\n",
        "        # collect the garbage\n",
        "        gc.collect()\n",
        "\n",
        "    # evaluation\n",
        "    model.eval()\n",
        "    for data in valid_dataset:\n",
        "        X, y = data\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        # predict\n",
        "        pred = model(X)\n",
        "        # compute loss\n",
        "        loss = loss_fn(pred, y.float())\n",
        "\n",
        "        round_pred = np.round(pred.detach().cpu())\n",
        "\n",
        "        valid_loss += loss.item()*X.size(0)\n",
        "        valid_y_true_lst.append(y.cpu())\n",
        "        valid_y_pred_lst.append(round_pred)\n",
        "\n",
        "        # delete locals\n",
        "        del X\n",
        "        del y\n",
        "        del loss\n",
        "        del pred\n",
        "\n",
        "        # clean the cache\n",
        "        if device == \"cuda\":\n",
        "            torch.cuda.empty_cache()\n",
        "        elif device == \"mps\":\n",
        "            torch.mps.empty_cache()\n",
        "        # collect the garbage\n",
        "        gc.collect()\n",
        "\n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = train_loss/len(train_dataset.sampler)\n",
        "    valid_loss = valid_loss/len(valid_dataset.sampler)\n",
        "\n",
        "    train_y_pred = torch.cat(train_y_pred_lst, dim=0).numpy()\n",
        "    train_y_pred = label_binarizer.fit_transform(train_y_pred)\n",
        "\n",
        "    train_y_true = torch.cat(train_y_true_lst, dim=0).numpy()\n",
        "    train_y_true = label_binarizer.fit_transform(train_y_true)\n",
        "\n",
        "    valid_y_pred = torch.cat(valid_y_pred_lst, dim=0).numpy()\n",
        "    valid_y_pred = label_binarizer.fit_transform(valid_y_pred)\n",
        "\n",
        "    valid_y_true = torch.cat(valid_y_true_lst, dim=0).numpy()\n",
        "    valid_y_true = label_binarizer.fit_transform(valid_y_true)\n",
        "\n",
        "    t_acc,t_f1s,t_rec_s,t_preci_s,t_ap_s = scoring(train_y_true,train_y_pred)\n",
        "    v_acc,v_f1s,v_rec_s,v_preci_s,v_ap_s = scoring(valid_y_true,valid_y_pred)\n",
        "    print(f\"AVG Training Loss: {round(train_loss,4)}\\nAVG Validation Loss: {round(valid_loss,4)}\")\n",
        "    print(f\"Accuracy: {round(t_acc,4)}\\nF1: {round(t_f1s,4)}\\nRecall: {round(t_rec_s,4)}\\nPrecision: {round(t_preci_s,4)}\\nAP: {round(t_ap_s,4)}\")\n",
        "    return train_loss,valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Mo-CFT_yBxc"
      },
      "outputs": [],
      "source": [
        "def test(test_dataset, model, loss_fn):\n",
        "\n",
        "  num_label = 12\n",
        "  class_label = list(range(num_label))\n",
        "  label_binarizer = MultiLabelBinarizer(classes=class_label)\n",
        "\n",
        "  test_loss = 0.\n",
        "  test_y_true_lst = []\n",
        "  test_y_pred_lst = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for data in valid_dataset_mvit:\n",
        "      X, y = data\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y.float())\n",
        "\n",
        "      round_pred = np.round(pred.detach().cpu())\n",
        "\n",
        "      test_loss += loss.item()*X.size(0)\n",
        "      test_y_true_lst.append(y.cpu())\n",
        "      test_y_pred_lst.append(round_pred)\n",
        "\n",
        "    test_loss = test_loss/len(train_dataset_mvit.sampler)\n",
        "\n",
        "    y_pred = torch.cat(test_y_pred_lst, dim=0).numpy()\n",
        "    y_pred = label_binarizer.fit_transform(y_pred)\n",
        "\n",
        "    y_true = torch.cat(test_y_true_lst, dim=0).numpy()\n",
        "    y_true = label_binarizer.fit_transform(y_true)\n",
        "\n",
        "    acc,f1s,rec_s,preci_s,ap_s = scoring(y_true,y_pred)\n",
        "\n",
        "    print(f\"AVG Test Loss: {round(test_loss,4)}\")\n",
        "    print(f\"Accuracy: {round(acc,4)}\\nF1: {round(f1s,4)}\\nRecall: {round(rec_s,4)}\\nPrecision: {round(preci_s,4)}\\nAP: {round(ap_s,4)}\")\n",
        "    return test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76DtNQjQCDcR"
      },
      "outputs": [],
      "source": [
        "#Train Model\n",
        "all_train_loss_swin = []\n",
        "all_valid_loss_swin = []\n",
        "epochs = 1\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss_swin, valid_loss_swin = train(train_dataset_swin,valid_dataset_swin, model_swin, loss_fn, optimizer_swin)\n",
        "    all_train_loss_swin.append(train_loss_swin)\n",
        "    all_valid_loss_swin.append(all_valid_loss_swin)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "779bdYgpDxG9"
      },
      "outputs": [],
      "source": [
        "#Test Model\n",
        "test_loss_swin = test(test_dataset_swin,model_swin,loss_fn)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}