{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.video import mvit_v2_s,MViT_V2_S_Weights\n",
    "from custom_dataset import CustomVidDataset\n",
    "from torchvideotransforms import video_transforms, volume_transforms\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_transform_list = [\n",
    "# \t\t\tvideo_transforms.Resize((224, 224)),\n",
    "#             volume_transforms.ClipToTensor()]\n",
    "video_transform_list = [MViT_V2_S_Weights.KINETICS400_V1.transforms()]\n",
    "transforms = video_transforms.Compose(video_transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_load = CustomImageDataset('img/label.csv','img/')\n",
    "data_vid_load = CustomVidDataset('data/test_label.csv','data/test',transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "    data_vid_load,\n",
    "    batch_size=30,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MViT(\n",
      "  (conv_proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))\n",
      "  (pos_encoding): PositionalEncoding()\n",
      "  (blocks): ModuleList(\n",
      "    (0): MultiscaleBlock(\n",
      "      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=96, out_features=96, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=96, out_features=384, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=384, out_features=96, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "    )\n",
      "    (1): MultiscaleBlock(\n",
      "      (pool_skip): Pool(\n",
      "        (pool): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=96, out_features=576, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.013333333333333334, mode=row)\n",
      "      (project): Linear(in_features=96, out_features=192, bias=True)\n",
      "    )\n",
      "    (2): MultiscaleBlock(\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=192, out_features=192, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=192, out_features=768, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=768, out_features=192, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.02666666666666667, mode=row)\n",
      "    )\n",
      "    (3): MultiscaleBlock(\n",
      "      (pool_skip): Pool(\n",
      "        (pool): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=192, out_features=1152, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.04000000000000001, mode=row)\n",
      "      (project): Linear(in_features=192, out_features=384, bias=True)\n",
      "    )\n",
      "    (4): MultiscaleBlock(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.05333333333333334, mode=row)\n",
      "    )\n",
      "    (5): MultiscaleBlock(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.06666666666666667, mode=row)\n",
      "    )\n",
      "    (6): MultiscaleBlock(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.08000000000000002, mode=row)\n",
      "    )\n",
      "    (7): MultiscaleBlock(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.09333333333333334, mode=row)\n",
      "    )\n",
      "    (8): MultiscaleBlock(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.10666666666666667, mode=row)\n",
      "    )\n",
      "    (9): MultiscaleBlock(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.12000000000000001, mode=row)\n",
      "    )\n",
      "    (10): MultiscaleBlock(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.13333333333333333, mode=row)\n",
      "    )\n",
      "    (11): MultiscaleBlock(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.14666666666666667, mode=row)\n",
      "    )\n",
      "    (12): MultiscaleBlock(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.16000000000000003, mode=row)\n",
      "    )\n",
      "    (13): MultiscaleBlock(\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.17333333333333334, mode=row)\n",
      "    )\n",
      "    (14): MultiscaleBlock(\n",
      "      (pool_skip): Pool(\n",
      "        (pool): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=384, out_features=2304, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.18666666666666668, mode=row)\n",
      "      (project): Linear(in_features=384, out_features=768, bias=True)\n",
      "    )\n",
      "    (15): MultiscaleBlock(\n",
      "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (attn): MultiscaleAttention(\n",
      "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "        (project): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (pool_q): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_k): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (pool_v): Pool(\n",
      "          (pool): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)\n",
      "          (norm_act): Sequential(\n",
      "            (0): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "        (1): GELU(approximate='none')\n",
      "        (2): Dropout(p=0.0, inplace=False)\n",
      "        (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        (4): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (head): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=True)\n",
      "    (1): Linear(in_features=768, out_features=400, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "pretained_mvit = mvit_v2_s(weights=\"KINETICS400_V1\")\n",
    "pretained_mvit.head = nn.Sequential(\n",
    "            nn.Linear(768,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 12),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "print(pretained_mvit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretained_mvit = pretained_mvit.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(pretained_mvit.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[30, 96, 8, 56, 56]' is invalid for input of size 451584000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretained_mvit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Compute prediction error\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Nida/dads-7202-final-project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Nida/dads-7202-final-project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Nida/dads-7202-final-project/venv/lib/python3.10/site-packages/torchvision/models/video/mvit.py:558\u001b[0m, in \u001b[0;36mMViT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    556\u001b[0m thw \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoding\u001b[38;5;241m.\u001b[39mtemporal_size,) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_encoding\u001b[38;5;241m.\u001b[39mspatial_size\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 558\u001b[0m     x, thw \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[1;32m    561\u001b[0m \u001b[38;5;66;03m# classifier \"token\" as used by standard language architectures\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Nida/dads-7202-final-project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Nida/dads-7202-final-project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Nida/dads-7202-final-project/venv/lib/python3.10/site-packages/torchvision/models/video/mvit.py:384\u001b[0m, in \u001b[0;36mMultiscaleBlock.forward\u001b[0;34m(self, x, thw)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, thw: Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    383\u001b[0m     x_norm1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_transposal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x)\n\u001b[0;32m--> 384\u001b[0m     x_attn, thw_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_norm1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_after_attn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproject(x_norm1)\n\u001b[1;32m    386\u001b[0m     x_skip \u001b[38;5;241m=\u001b[39m x \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool_skip \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool_skip(x, thw)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Nida/dads-7202-final-project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Nida/dads-7202-final-project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Nida/dads-7202-final-project/venv/lib/python3.10/site-packages/torchvision/models/video/mvit.py:293\u001b[0m, in \u001b[0;36mMultiscaleAttention.forward\u001b[0;34m(self, x, thw)\u001b[0m\n\u001b[1;32m    290\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqkv(x)\u001b[38;5;241m.\u001b[39mreshape(B, N, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39munbind(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool_k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 293\u001b[0m     k, k_thw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     k_thw \u001b[38;5;241m=\u001b[39m thw\n",
      "File \u001b[0;32m~/Desktop/Nida/dads-7202-final-project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Nida/dads-7202-final-project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Nida/dads-7202-final-project/venv/lib/python3.10/site-packages/torchvision/models/video/mvit.py:89\u001b[0m, in \u001b[0;36mPool.forward\u001b[0;34m(self, x, thw)\u001b[0m\n\u001b[1;32m     87\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     88\u001b[0m B, N, C \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m---> 89\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# normalizing prior pooling is useful when we use BN which can be absorbed to speed up inference\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_before_pool \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_act \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[30, 96, 8, 56, 56]' is invalid for input of size 451584000"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(data_loader, pretained_mvit, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
